{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights=None, input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='mean_squared_error', metrics=['accuracy'])\n",
    "    encoder=Model(inputs=inputs, outputs=drop5)\n",
    "    # model.summary()\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_path = '../dataset/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "\n",
    "df_train = pd.read_csv(train_txt_path, sep=\" \", header=None)\n",
    "df_train.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_train = df_train.drop(columns=\"null\")\n",
    "\n",
    "dev_txt_path = '../dataset/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "\n",
    "df_dev = pd.read_csv(dev_txt_path, sep=\" \", header=None)\n",
    "df_dev.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_dev = df_dev.drop(columns=\"null\")\n",
    "\n",
    "eval_txt_path = '../dataset/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "\n",
    "df_eval = pd.read_csv(eval_txt_path, sep=\" \", header=None)\n",
    "df_eval.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_eval = df_eval.drop(columns=\"null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i parametri da testare sono:\n",
    "# nfft = 64, hop_size = 32 \n",
    "# nfft = 128, hop_size = 64 fatto\n",
    "# nfft = 256, hop_size = 128 \n",
    "# nffr = 512, hop_size = 256\n",
    "\n",
    "nfft = 64\n",
    "hop_size = 32 \n",
    "\n",
    "alg_list = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06']\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1 #=16 per nfft > 512\n",
    "\n",
    "input_size = nfft // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f87dc0ff84c5b9fb2f5f88cae9297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_feat_root_path = '../features/bicoherences/train_nfft_{}_hop_size_{}'.format(nfft, hop_size)\n",
    "\n",
    "for alg in tqdm(alg_list, total=len(alg_list)):\n",
    "    \n",
    "    # carichiamo il modello corrispondente dalla cartella \n",
    "    model_folder = '../features/unet/models/train_nfft_{}_hop_size_{}_alg_{}.ckpt'.format(\n",
    "        nfft, hop_size, alg)\n",
    "    \n",
    "    \n",
    "    model, encoder = unet(model_folder, (input_size, input_size, 1))\n",
    "\n",
    "    break\n",
    "    # creiamo un campo in un dataframe per ora vuoto\n",
    "    feat_name = 'unet_mse_alg_{}'.format(nfft, hop_size, alg)\n",
    "    df_train[feat_name] = np.nan\n",
    "    \n",
    "    mag_volume = []\n",
    "    for index, row in df_train.iterrows():\n",
    "        feat_path = os.path.join(train_feat_root_path, row['audio_filename'] + '.npy')\n",
    "        bicoh = np.load(feat_path)\n",
    "        mag = np.abs(bicoh)\n",
    "        \n",
    "        mag_volume.append(mag)\n",
    "        \n",
    "    mag_volume = np.array(mag_volume)\n",
    "    mag_volume = mag_volume[..., np.newaxis]\n",
    "    \n",
    "    output = model.predict(mag_volume, batch_size=batch_size)\n",
    "    compressed = encoder.predict(mag_volume, batch_size=batch_size)\n",
    "    output_compressed = encoder.predict(output, batch_size=batch_size)\n",
    "            \n",
    "    mse = np.mean(np.square(compressed - output_compressed), axis=(1,2,3))\n",
    "        \n",
    "    df_train.at[:, feat_name] = mse\n",
    "    \n",
    "df_train.to_pickle('../features/unet/train_nfft_{}_hop_size_{}.pkl'.format(nfft, hop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_feat_root_path = '../features/bicoherences/dev_nfft_{}_hop_size_{}'.format(nfft, hop_size)\n",
    "\n",
    "for alg in alg_list:\n",
    "    \n",
    "    model_folder = '../features/unet/models/train_nfft_{}_hop_size_{}_alg_{}.ckpt'.format(\n",
    "        nfft, hop_size, alg)\n",
    "    \n",
    "    \n",
    "    model, encoder = unet(model_folder, (input_size, input_size, 1))\n",
    "\n",
    "\n",
    "    # creiamo un campo in un dataframe per ora vuoto\n",
    "    feat_name = 'unet_mse_alg_{}'.format(alg)\n",
    "    df_dev[feat_name] = np.nan\n",
    "    \n",
    "    mag_volume = []\n",
    "    for index, row in tqdm(df_dev.iterrows(), total=len(df_dev)):\n",
    "        feat_path = os.path.join(dev_feat_root_path, row['audio_filename'] + '.npy')\n",
    "        bicoh = np.load(feat_path)\n",
    "        mag = np.abs(bicoh)\n",
    "        \n",
    "        mag_volume.append(mag)\n",
    "        \n",
    "    mag_volume = np.array(mag_volume)\n",
    "    mag_volume = mag_volume[..., np.newaxis]\n",
    "    \n",
    "    output = model.predict(mag_volume, batch_size=batch_size)\n",
    "    compressed = encoder.predict(mag_volume, batch_size=batch_size)\n",
    "    output_compressed = encoder.predict(output, batch_size=batch_size)\n",
    "            \n",
    "    mse = np.mean(np.square(compressed - output_compressed), axis=(1,2,3))\n",
    "        \n",
    "    df_dev.at[:, feat_name] = mse\n",
    "    break\n",
    "\n",
    "#df_dev.to_pickle('../features/unet/dev_nfft_{}_hop_size_{}.pkl'.format(nfft, hop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_feat_root_path = '../features/bicoherences/eval_nfft_{}_hop_size_{}'.format(\n",
    "    nfft, hop_size)\n",
    "\n",
    "for alg in alg_list:\n",
    "    \n",
    "    model_folder = '../features/unet/models/train_nfft_{}_hop_size_{}_alg_{}.ckpt'.format(\n",
    "        nfft, hop_size, alg)\n",
    "    \n",
    "    \n",
    "    model, encoder = unet(model_folder, (input_size, input_size, 1))\n",
    "\n",
    "\n",
    "    # creiamo un campo in un dataframe per ora vuoto\n",
    "    feat_name = 'unet_mse_alg_{}'.format(nfft, hop_size, alg)\n",
    "    df_eval[feat_name] = np.nan\n",
    "    \n",
    "    mag_volume = []\n",
    "    for index, row in tqdm(df_eval.iterrows(), total=len(df_eval)):\n",
    "        feat_path = os.path.join(eval_feat_root_path, row['audio_filename'] + '.npy')\n",
    "        bicoh = np.load(feat_path)\n",
    "        mag = np.abs(bicoh)\n",
    "        \n",
    "        mag_volume = mag\n",
    "        \n",
    "        #mag_volume = np.array(mag_volume)\n",
    "        mag_volume = mag_volume[np.newaxis, ..., np.newaxis]\n",
    "    \n",
    "        output = model.predict(mag_volume, batch_size=batch_size)\n",
    "        compressed = encoder.predict(mag_volume, batch_size=batch_size)\n",
    "        output_compressed = encoder.predict(output, batch_size=batch_size)\n",
    "            \n",
    "        mse = np.mean(np.square(compressed - output_compressed))\n",
    "        \n",
    "        df_eval.at[index, feat_name] = mse\n",
    "\n",
    "df_eval.to_pickle('../features/unet/eval_nfft_{}_hop_size_{}.pkl'.format(nfft, hop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
